# PII Obfuscation with Custom-Trained Models

This project demonstrates how to generate a synthetic dataset using a Large Language Model (LLM) and then use that data to fine-tune a smaller, more efficient NLP model for Personally Identifiable Information (PII) obfuscation. The primary focus is the Jupyter Notebook, which walks through the entire process from data generation to model training and evaluation.

An accompanying Flask application is also included to show how the fine-tuned model can be deployed as a simple REST API.

## Core Idea

Instead of relying solely on large, general-purpose LLMs for PII detection (which can be costly and slow), this project explores a more targeted approach:

1.  **Use an LLM once** to generate a high-quality, domain-specific training dataset.
2.  **Fine-tune a smaller model** (like BERT) on this custom dataset.
3.  **Deploy the smaller model** for fast, efficient, and offline-capable PII detection and obfuscation.

## Notebook: Generating PII Training Data with an LLM

The notebook `notebook/Using an LLM to generate training data for smaller targeted NLP models copy.ipynb` is the centerpiece of this project. It provides a step-by-step guide to:

1.  **Synthetic Data Generation**: Uses GPT-4o-mini to generate realistic customer service interactions containing various types of PII (names, emails, phone numbers, etc.).
2.  **Data Labeling & Obfuscation**: Employs a few-shot prompting strategy to have the LLM label and obfuscate the PII in the generated text, creating a ready-to-use dataset for training.
3.  **Data Preprocessing**: Cleans and tokenizes the text, aligning the PII labels with the word pieces generated by the BERT tokenizer.
4.  **Model Fine-Tuning**: Leverages the Hugging Face `transformers` library to fine-tune a `google/bert_uncased_L-10_H-512_A-8` model for token classification on our custom dataset.
5.  **Evaluation**: Assesses the model's performance using a confusion matrix and classification report to understand its strengths and weaknesses in identifying different PII entities.
6.  **Application**: Demonstrates how to use the fine-tuned model to predict and redact PII from new, unseen text.

## Flask Application

The `/app` directory contains a simple Flask web server that demonstrates how to serve the fine-tuned PII obfuscation model.

-   **Purpose**: To provide a basic REST API endpoint (`/obfuscate`) that accepts text and returns the obfuscated version.
-   **Note**: This is a lightweight demonstration. A more detailed README for the application can be found in `app/README.md`.

## Setup and Usage

1.  **Clone the repository** (if applicable).

2.  **Create and activate a virtual environment**:
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install dependencies**:
    *For the notebook and general setup:*
    ```bash
    pip install -r requirements.txt 
    ```
    *For the Flask app:*
    ```bash
    pip install -r app/requirements.txt
    ```

4.  **Download the spaCy model** (for the Flask app):
    ```bash
    python -m spacy download en_core_web_sm
    ```

5.  **Run the Notebook**:
    - Launch Jupyter Lab or Jupyter Notebook and open `notebook/Using an LLM to generate training data for smaller targeted NLP models copy.ipynb`.
    - Execute the cells to generate data and train the model.

6.  **Run the Flask Application**:
    ```bash
    python app/app.py
    ```
    The server will start on `http://127.0.0.1:5000`.

## Project Structure

```
PII_Obfuscation/
├── README.md
├── requirements.txt
├── notebook/
│   └── Using an LLM to generate training data for smaller targeted NLP models copy.ipynb
└── app/
    ├── app.py              # Main Flask application file
    ├── README.md           # App-specific README
    ├── requirements.txt    # App-specific dependencies
    └── inference/
        └── obfuscate.py    # Core PII obfuscation logic
```

## License

This project is licensed under the MIT License.